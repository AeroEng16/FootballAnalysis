{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtNQ7FBDDA/O6Y+/7kFwzV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AeroEng16/FootballAnalysis/blob/main/naryaHomoraphyRecreation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to recreate\n",
        "# https://github.com/DonsetPG/narya/blob/master/narya/tracker/homography_estimator.py\n",
        "\n",
        "\n",
        "!pip install segmentation-models\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchvision.transforms import Normalize\n",
        "\n",
        "\n",
        "#import mxnet as mx\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm\n",
        "\n",
        "\n",
        "#from gluoncv.data.transforms.presets.ssd import transform_test\n",
        "\n",
        "#import mxnet as mx\n",
        "import tensorflow as tf\n",
        "\n",
        "RESNET_ARCHI_TF_KERAS_PATH = (\n",
        "    \"https://storage.googleapis.com/narya-bucket-1/models/deep_homo_model_1.h5\"\n",
        ")\n",
        "RESNET_ARCHI_TF_KERAS_NAME = \"deep_homo_model_1.h5\"\n",
        "RESNET_ARCHI_TF_KERAS_TOTAR = False"
      ],
      "metadata": {
        "id": "PdwMjarvIa3D",
        "outputId": "d2125011-5050-4cda-a190-a6cf780d6109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from segmentation-models) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.11/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.11/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.12.1)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def to_numpy(var):\n",
        "    \"\"\"Parse a Torch variable to a numpy array\n",
        "\n",
        "    Arguments:\n",
        "        var: torch variable\n",
        "    Returns:\n",
        "        a np.array with the same value as var\n",
        "    Raises:\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return var.numpy()\n",
        "    except:\n",
        "        return var.detach().numpy()\n",
        "\n",
        "\n",
        "def to_torch(np_array):\n",
        "    \"\"\"Parse a numpy array to a torch variable\n",
        "\n",
        "    Arguments:\n",
        "        np_array: a np.array\n",
        "    Returns:\n",
        "        a torch Var with the same value as the np_array\n",
        "    Raises:\n",
        "\n",
        "    \"\"\"\n",
        "    tensor = torch.from_numpy(np_array).float()\n",
        "    return torch.autograd.Variable(tensor, requires_grad=False)\n",
        "\n",
        "def torch_img_to_np_img(torch_img):\n",
        "    \"\"\"Convert a torch image to a numpy image\n",
        "\n",
        "    Arguments:\n",
        "        torch_img: Tensor of shape (B,C,H,W) or (C,H,W)\n",
        "    Returns:\n",
        "        a np.array of shape (B,H,W,C) or (H,W,C)\n",
        "    Raises:\n",
        "        ValueError: If this is not a Torch tensor\n",
        "    \"\"\"\n",
        "    if isinstance(torch_img, np.ndarray):\n",
        "        return torch_img\n",
        "    assert isinstance(torch_img, torch.Tensor), \"cannot process data type: {0}\".format(\n",
        "        type(torch_img)\n",
        "    )\n",
        "    if len(torch_img.shape) == 4 and (\n",
        "        torch_img.shape[1] == 3 or torch_img.shape[1] == 1\n",
        "    ):\n",
        "        return np.transpose(torch_img.detach().cpu().numpy(), (0, 2, 3, 1))\n",
        "    if len(torch_img.shape) == 3 and (\n",
        "        torch_img.shape[0] == 3 or torch_img.shape[0] == 1\n",
        "    ):\n",
        "        return np.transpose(torch_img.detach().cpu().numpy(), (1, 2, 0))\n",
        "    elif len(torch_img.shape) == 2:\n",
        "        return torch_img.detach().cpu().numpy()\n",
        "    else:\n",
        "        raise ValueError(\"cannot process this image\")\n",
        "\n",
        "\n",
        "def np_img_to_torch_img(np_img):\n",
        "    \"\"\"Convert a np image to a torch image\n",
        "\n",
        "    Arguments:\n",
        "        np_img: a np.array of shape (B,H,W,C) or (H,W,C)\n",
        "    Returns:\n",
        "        a Tensor of shape (B,C,H,W) or (C,H,W)\n",
        "    Raises:\n",
        "        ValueError: If this is not a np.array\n",
        "    \"\"\"\n",
        "    if isinstance(np_img, torch.Tensor):\n",
        "        return np_img\n",
        "    assert isinstance(np_img, np.ndarray), \"cannot process data type: {0}\".format(\n",
        "        type(np_img)\n",
        "    )\n",
        "    if len(np_img.shape) == 4 and (np_img.shape[3] == 3 or np_img.shape[3] == 1):\n",
        "        return to_torch(np.transpose(np_img, (0, 3, 1, 2)))\n",
        "    if len(np_img.shape) == 3 and (np_img.shape[2] == 3 or np_img.shape[2] == 1):\n",
        "        return to_torch(np.transpose(np_img, (2, 0, 1)))\n",
        "    elif len(np_img.shape) == 2:\n",
        "        return to_torch(np_img)\n",
        "    else:\n",
        "        raise ValueError(\"cannot process this image\")\n",
        "\n",
        "\n",
        "def normalize_single_image_torch(image, img_mean=None, img_std=None):\n",
        "    \"\"\"Normalize a Torch tensor\n",
        "\n",
        "    Arguments:\n",
        "        image: Torch Tensor of shape (C,W,H)\n",
        "        img_mean: List of mean per channel (e.g.: [0.485, 0.456, 0.406])\n",
        "        img_std: List of std per channel (e.g.: [0.229, 0.224, 0.225])\n",
        "    Returns:\n",
        "        image: Torch Tensor of shape (C,W,H), the normalized image\n",
        "    Raises:\n",
        "        ValueError: If the shape of the image is not of lenth 3\n",
        "        ValueError: If the image is not a torch Tensor\n",
        "    \"\"\"\n",
        "    if len(image.shape) != 3:\n",
        "        raise ValueError(\n",
        "            \"The len(shape) of the image is {}, not 3\".format(len(image.shape))\n",
        "        )\n",
        "    if isinstance(image, torch.Tensor) == False:\n",
        "        raise ValueError(\"The image is not a torch Tensor\")\n",
        "    if img_mean is None and img_std is None:\n",
        "        img_mean = torch.mean(image, dim=(1, 2)).view(-1, 1, 1)\n",
        "        img_std = image.contiguous().view(image.size(0), -1).std(-1).view(-1, 1, 1)\n",
        "        image = (image - img_mean) / img_std\n",
        "    else:\n",
        "        image = Normalize(img_mean, img_std, inplace=False)(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def denormalize(x):\n",
        "    \"\"\"Scale image to range [0,1]\n",
        "\n",
        "    Arguments:\n",
        "        x: np.array, an image\n",
        "    Returns:\n",
        "        x: np.array, the scaled image\n",
        "    Raises:\n",
        "\n",
        "    \"\"\"\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)\n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "LO5VNUwbXWOK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\"\"\"Builds the preprocessing function for each model. They all use torch/keras/gluoncv functions depending on the model.\n",
        "Arguments:\n",
        "    input_shape: Tuple of integer, the input_shape the model needs to take\n",
        "Returns:\n",
        "    preprocessing: function that takes an image as input, and returns the preprocessed image.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _build_keypoint_preprocessing(input_shape, backbone):\n",
        "    \"\"\"Builds the preprocessing function for the Field Keypoint Detector Model.\n",
        "\n",
        "    \"\"\"\n",
        "    sm_preprocessing = sm.get_preprocessing(backbone)\n",
        "\n",
        "    def preprocessing(input_img, **kwargs):\n",
        "\n",
        "        to_normalize = False if np.percentile(input_img, 98) > 1.0 else True\n",
        "\n",
        "        if len(input_img.shape) == 4:\n",
        "            print(\n",
        "                \"Only preprocessing single image, we will consider the first one of the batch\"\n",
        "            )\n",
        "            image = input_img[0] * 255.0 if to_normalize else input_img[0] * 1.0\n",
        "        else:\n",
        "            image = input_img * 255.0 if to_normalize else input_img * 1.0\n",
        "\n",
        "        image = cv2.resize(image, input_shape)\n",
        "        image = sm_preprocessing(image)\n",
        "        return image\n",
        "\n",
        "    return preprocessing\n",
        "\n",
        "\n",
        "\n",
        "def _build_homo_preprocessing(input_shape):\n",
        "    \"\"\"Builds the preprocessing function for the Deep Homography estimation Model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def preprocessing(input_img, **kwargs):\n",
        "\n",
        "        if len(input_img.shape) == 4:\n",
        "            print(\n",
        "                \"Only preprocessing single image, we will consider the first one of the batch\"\n",
        "            )\n",
        "            image = input_img[0]\n",
        "        else:\n",
        "            image = input_img\n",
        "\n",
        "        image = cv2.resize(image, input_shape)\n",
        "        image = torch_img_to_np_img(\n",
        "            normalize_single_image_torch(np_img_to_torch_img(image))\n",
        "        )\n",
        "        return image\n",
        "\n",
        "    return preprocessing\n"
      ],
      "metadata": {
        "id": "IKDzvG5wIyAZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def pyramid_layer(\n",
        "    x, indx, activation=\"tanh\", output_size=8, nb_neurons=[512, 512, 256, 128]\n",
        "):\n",
        "    \"\"\"Fully connected layers to add at the end of a network.\n",
        "\n",
        "    Arguments:\n",
        "        x: a tf.keras Tensor as input\n",
        "        indx: Integer, an index to add to the name of the layers\n",
        "        activation: String, name of the activation function to add at the end\n",
        "        output_size: Size of the last layer, number of outputs\n",
        "        nb_neurons: Size of the Dense layer to add\n",
        "    Returns:\n",
        "        output: a tf.keras Tensor as output\n",
        "    Raises:\n",
        "\n",
        "    \"\"\"\n",
        "    dense_name_base = \"full_\" + str(indx)\n",
        "    for indx, neuron in enumerate(nb_neurons):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            neuron, name=dense_name_base + str(neuron) + \"_\" + str(indx)\n",
        "        )(x)\n",
        "    x = tf.keras.layers.Dense(output_size, name=dense_name_base + \"output\")(x)\n",
        "    output = tf.keras.layers.Activation(activation)(x)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "3nBwEbmFIZif"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1TTtiTGSIODc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def _build_resnet18():\n",
        "    \"\"\"Builds a resnet18 model in keras from a .h5 file.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "    Returns:\n",
        "        a tf.keras.models.Model\n",
        "    Raises:\n",
        "    \"\"\"\n",
        "    resnet18_path_to_file = tf.keras.utils.get_file(\n",
        "        RESNET_ARCHI_TF_KERAS_NAME,\n",
        "        RESNET_ARCHI_TF_KERAS_PATH,\n",
        "        RESNET_ARCHI_TF_KERAS_TOTAR,\n",
        "    )\n",
        "\n",
        "    resnet18 = tf.keras.models.load_model(resnet18_path_to_file)\n",
        "    resnet18.compile()\n",
        "\n",
        "    inputs = resnet18.input\n",
        "    outputs = resnet18.layers[-2].output\n",
        "\n",
        "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"custom_resnet18\")\n",
        "\n",
        "\n",
        "class DeepHomoModel:\n",
        "    \"\"\"Class for Keras Models to predict the corners displacement from an image. These corners can then get used\n",
        "    to compute the homography.\n",
        "\n",
        "    Arguments:\n",
        "        pretrained: Boolean, if the model is loaded pretrained on ImageNet or not\n",
        "        input_shape: Tuple, shape of the model's input\n",
        "    Call arguments:\n",
        "        input_img: a np.array of shape input_shape\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pretrained=False, input_shape=(256, 256)):\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        self.resnet_18 = _build_resnet18()\n",
        "\n",
        "        inputs = tf.keras.layers.Input((self.input_shape[0], self.input_shape[1], 3))\n",
        "        x = self.resnet_18(inputs)\n",
        "        outputs = pyramid_layer(x, 2)\n",
        "\n",
        "        self.model = tf.keras.models.Model(\n",
        "            inputs=[inputs], outputs=outputs, name=\"DeepHomoPyramidalFull\"\n",
        "        )\n",
        "\n",
        "        self.preprocessing = _build_homo_preprocessing(input_shape)\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "\n",
        "        img = self.preprocessing(input_img)\n",
        "        corners = self.model.predict(np.array([img]))\n",
        "\n",
        "        return corners\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        try:\n",
        "            self.model.load_weights(weights_path)\n",
        "            print(\"Succesfully loaded weights from {}\".format(weights_path))\n",
        "        except:\n",
        "            orig_weights = \"Randomly\"\n",
        "            print(\n",
        "                \"Could not load weights from {}, weights will be loaded {}\".format(\n",
        "                    weights_path, orig_weights\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KeypointDetectorModel:\n",
        "    \"\"\"Class for Keras Models to predict the keypoint in an image. These keypoints can then be used to\n",
        "    compute the homography.\n",
        "\n",
        "    Arguments:\n",
        "        backbone: String, the backbone we want to use\n",
        "        model_choice: The model architecture. ('FPN','Unet','Linknet')\n",
        "        num_classes: Integer, number of mask to compute (= number of keypoints)\n",
        "        input_shape: Tuple, shape of the model's input\n",
        "    Call arguments:\n",
        "        input_img: a np.array of shape input_shape\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone=\"efficientnetb3\",\n",
        "        model_choice=\"FPN\",\n",
        "        num_classes=29,\n",
        "        input_shape=(320, 320),\n",
        "    ):\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.classes = [str(i) for i in range(num_classes)] + [\"background\"]\n",
        "        self.backbone = backbone\n",
        "\n",
        "        n_classes = len(self.classes)\n",
        "        activation = \"softmax\"\n",
        "\n",
        "        if model_choice == \"FPN\":\n",
        "            self.model = sm.FPN(\n",
        "                self.backbone,\n",
        "                classes=n_classes,\n",
        "                activation=activation,\n",
        "                input_shape=(input_shape[0], input_shape[1], 3),\n",
        "                encoder_weights=\"imagenet\",\n",
        "            )\n",
        "        else:\n",
        "            self.model = None\n",
        "            print(\"{} is not used yet\".format(model_choice))\n",
        "\n",
        "        self.preprocessing = _build_keypoint_preprocessing(input_shape, backbone)\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "\n",
        "        img = self.preprocessing(input_img)\n",
        "        pr_mask = self.model.predict(np.array([img]))\n",
        "        return pr_mask\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        try:\n",
        "            self.model.load_weights(weights_path)\n",
        "            print(\"Succesfully loaded weights from {}\".format(weights_path))\n",
        "        except:\n",
        "            orig_weights = \"from Imagenet\"\n",
        "            print(\n",
        "                \"Could not load weights from {}, weights will be loaded {}\".format(\n",
        "                    weights_path, orig_weights\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "zP5TYNyEIRxa"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}