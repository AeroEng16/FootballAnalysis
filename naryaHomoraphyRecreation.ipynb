{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtu4Edb8yYcWvjoes2YBAK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AeroEng16/FootballAnalysis/blob/main/naryaHomoraphyRecreation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to recreate\n",
        "# https://github.com/DonsetPG/narya/blob/master/narya/tracker/homography_estimator.py\n",
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "#import mxnet as mx\n",
        "import numpy as np\n",
        "import cv2\n",
        "import segmentation_models as sm\n",
        "from gluoncv.data.transforms.presets.ssd import transform_test\n",
        "from ..utils.image import (\n",
        "    np_img_to_torch_img,\n",
        "    normalize_single_image_torch,\n",
        "    torch_img_to_np_img,\n",
        ")\n",
        "#import mxnet as mx\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "from ..preprocessing.image import _build_homo_preprocessing\n",
        "from ..preprocessing.image import _build_keypoint_preprocessing\n",
        "\n",
        "RESNET_ARCHI_TF_KERAS_PATH = (\n",
        "    \"https://storage.googleapis.com/narya-bucket-1/models/deep_homo_model_1.h5\"\n",
        ")\n",
        "RESNET_ARCHI_TF_KERAS_NAME = \"deep_homo_model_1.h5\"\n",
        "RESNET_ARCHI_TF_KERAS_TOTAR = False"
      ],
      "metadata": {
        "id": "PdwMjarvIa3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\"\"\"Builds the preprocessing function for each model. They all use torch/keras/gluoncv functions depending on the model.\n",
        "Arguments:\n",
        "    input_shape: Tuple of integer, the input_shape the model needs to take\n",
        "Returns:\n",
        "    preprocessing: function that takes an image as input, and returns the preprocessed image.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _build_reid_preprocessing(input_shape):\n",
        "    \"\"\"Builds the preprocessing function for the Re Identification model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def preprocessing(input_img, **kwargs):\n",
        "\n",
        "        to_normalize = True if np.percentile(input_img, 98) > 1.0 else False\n",
        "\n",
        "        if len(input_img.shape) == 4:\n",
        "            print(\n",
        "                \"Only preprocessing single image, we will consider the first one of the batch\"\n",
        "            )\n",
        "            image = input_img[0] / 255.0 if to_normalize else input_img[0] / 1.0\n",
        "        else:\n",
        "            image = input_img / 255.0 if to_normalize else input_img / 1.0\n",
        "\n",
        "        image = cv2.resize(image, (input_shape[1], input_shape[0]))\n",
        "\n",
        "        image = np_img_to_torch_img(image)\n",
        "        image = normalize_single_image_torch(\n",
        "            image, img_mean=[0.485, 0.456, 0.406], img_std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "        return image.expand(1, -1, -1, -1)\n",
        "\n",
        "    return preprocessing\n",
        "\n",
        "\n",
        "def _build_keypoint_preprocessing(input_shape, backbone):\n",
        "    \"\"\"Builds the preprocessing function for the Field Keypoint Detector Model.\n",
        "\n",
        "    \"\"\"\n",
        "    sm_preprocessing = sm.get_preprocessing(backbone)\n",
        "\n",
        "    def preprocessing(input_img, **kwargs):\n",
        "\n",
        "        to_normalize = False if np.percentile(input_img, 98) > 1.0 else True\n",
        "\n",
        "        if len(input_img.shape) == 4:\n",
        "            print(\n",
        "                \"Only preprocessing single image, we will consider the first one of the batch\"\n",
        "            )\n",
        "            image = input_img[0] * 255.0 if to_normalize else input_img[0] * 1.0\n",
        "        else:\n",
        "            image = input_img * 255.0 if to_normalize else input_img * 1.0\n",
        "\n",
        "        image = cv2.resize(image, input_shape)\n",
        "        image = sm_preprocessing(image)\n",
        "        return image\n",
        "\n",
        "    return preprocessing\n",
        "\n",
        "\n",
        "def _build_tracking_preprocessing(input_shape):\n",
        "    \"\"\"Builds the preprocessing function for the Player/Ball Tracking Model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def preprocessing(input_img, **kwargs):\n",
        "\n",
        "        to_normalize = False if np.percentile(input_img, 98) > 1.0 else True\n",
        "\n",
        "        if len(input_img.shape) == 4:\n",
        "            print(\n",
        "                \"Only preprocessing single image, we will consider the first one of the batch\"\n",
        "            )\n",
        "            image = input_img[0] * 255.0 if to_normalize else input_img[0] * 1.0\n",
        "        else:\n",
        "            image = input_img * 255.0 if to_normalize else input_img * 1.0\n",
        "\n",
        "        image = cv2.resize(image, input_shape)\n",
        "        x, _ = transform_test(mx.nd.array(image), min(input_shape))\n",
        "        return x\n",
        "\n",
        "    return preprocessing\n",
        "\n",
        "\n",
        "def _build_homo_preprocessing(input_shape):\n",
        "    \"\"\"Builds the preprocessing function for the Deep Homography estimation Model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def preprocessing(input_img, **kwargs):\n",
        "\n",
        "        if len(input_img.shape) == 4:\n",
        "            print(\n",
        "                \"Only preprocessing single image, we will consider the first one of the batch\"\n",
        "            )\n",
        "            image = input_img[0]\n",
        "        else:\n",
        "            image = input_img\n",
        "\n",
        "        image = cv2.resize(image, input_shape)\n",
        "        image = torch_img_to_np_img(\n",
        "            normalize_single_image_torch(np_img_to_torch_img(image))\n",
        "        )\n",
        "        return image\n",
        "\n",
        "    return preprocessing\n"
      ],
      "metadata": {
        "id": "IKDzvG5wIyAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def pyramid_layer(\n",
        "    x, indx, activation=\"tanh\", output_size=8, nb_neurons=[512, 512, 256, 128]\n",
        "):\n",
        "    \"\"\"Fully connected layers to add at the end of a network.\n",
        "\n",
        "    Arguments:\n",
        "        x: a tf.keras Tensor as input\n",
        "        indx: Integer, an index to add to the name of the layers\n",
        "        activation: String, name of the activation function to add at the end\n",
        "        output_size: Size of the last layer, number of outputs\n",
        "        nb_neurons: Size of the Dense layer to add\n",
        "    Returns:\n",
        "        output: a tf.keras Tensor as output\n",
        "    Raises:\n",
        "\n",
        "    \"\"\"\n",
        "    dense_name_base = \"full_\" + str(indx)\n",
        "    for indx, neuron in enumerate(nb_neurons):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            neuron, name=dense_name_base + str(neuron) + \"_\" + str(indx)\n",
        "        )(x)\n",
        "    x = tf.keras.layers.Dense(output_size, name=dense_name_base + \"output\")(x)\n",
        "    output = tf.keras.layers.Activation(activation)(x)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "3nBwEbmFIZif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TTtiTGSIODc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def _build_resnet18():\n",
        "    \"\"\"Builds a resnet18 model in keras from a .h5 file.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "    Returns:\n",
        "        a tf.keras.models.Model\n",
        "    Raises:\n",
        "    \"\"\"\n",
        "    resnet18_path_to_file = tf.keras.utils.get_file(\n",
        "        RESNET_ARCHI_TF_KERAS_NAME,\n",
        "        RESNET_ARCHI_TF_KERAS_PATH,\n",
        "        RESNET_ARCHI_TF_KERAS_TOTAR,\n",
        "    )\n",
        "\n",
        "    resnet18 = tf.keras.models.load_model(resnet18_path_to_file)\n",
        "    resnet18.compile()\n",
        "\n",
        "    inputs = resnet18.input\n",
        "    outputs = resnet18.layers[-2].output\n",
        "\n",
        "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"custom_resnet18\")\n",
        "\n",
        "\n",
        "class DeepHomoModel:\n",
        "    \"\"\"Class for Keras Models to predict the corners displacement from an image. These corners can then get used\n",
        "    to compute the homography.\n",
        "\n",
        "    Arguments:\n",
        "        pretrained: Boolean, if the model is loaded pretrained on ImageNet or not\n",
        "        input_shape: Tuple, shape of the model's input\n",
        "    Call arguments:\n",
        "        input_img: a np.array of shape input_shape\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pretrained=False, input_shape=(256, 256)):\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        self.resnet_18 = _build_resnet18()\n",
        "\n",
        "        inputs = tf.keras.layers.Input((self.input_shape[0], self.input_shape[1], 3))\n",
        "        x = self.resnet_18(inputs)\n",
        "        outputs = pyramid_layer(x, 2)\n",
        "\n",
        "        self.model = tf.keras.models.Model(\n",
        "            inputs=[inputs], outputs=outputs, name=\"DeepHomoPyramidalFull\"\n",
        "        )\n",
        "\n",
        "        self.preprocessing = _build_homo_preprocessing(input_shape)\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "\n",
        "        img = self.preprocessing(input_img)\n",
        "        corners = self.model.predict(np.array([img]))\n",
        "\n",
        "        return corners\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        try:\n",
        "            self.model.load_weights(weights_path)\n",
        "            print(\"Succesfully loaded weights from {}\".format(weights_path))\n",
        "        except:\n",
        "            orig_weights = \"Randomly\"\n",
        "            print(\n",
        "                \"Could not load weights from {}, weights will be loaded {}\".format(\n",
        "                    weights_path, orig_weights\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KeypointDetectorModel:\n",
        "    \"\"\"Class for Keras Models to predict the keypoint in an image. These keypoints can then be used to\n",
        "    compute the homography.\n",
        "\n",
        "    Arguments:\n",
        "        backbone: String, the backbone we want to use\n",
        "        model_choice: The model architecture. ('FPN','Unet','Linknet')\n",
        "        num_classes: Integer, number of mask to compute (= number of keypoints)\n",
        "        input_shape: Tuple, shape of the model's input\n",
        "    Call arguments:\n",
        "        input_img: a np.array of shape input_shape\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone=\"efficientnetb3\",\n",
        "        model_choice=\"FPN\",\n",
        "        num_classes=29,\n",
        "        input_shape=(320, 320),\n",
        "    ):\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.classes = [str(i) for i in range(num_classes)] + [\"background\"]\n",
        "        self.backbone = backbone\n",
        "\n",
        "        n_classes = len(self.classes)\n",
        "        activation = \"softmax\"\n",
        "\n",
        "        if model_choice == \"FPN\":\n",
        "            self.model = sm.FPN(\n",
        "                self.backbone,\n",
        "                classes=n_classes,\n",
        "                activation=activation,\n",
        "                input_shape=(input_shape[0], input_shape[1], 3),\n",
        "                encoder_weights=\"imagenet\",\n",
        "            )\n",
        "        else:\n",
        "            self.model = None\n",
        "            print(\"{} is not used yet\".format(model_choice))\n",
        "\n",
        "        self.preprocessing = _build_keypoint_preprocessing(input_shape, backbone)\n",
        "\n",
        "    def __call__(self, input_img):\n",
        "\n",
        "        img = self.preprocessing(input_img)\n",
        "        pr_mask = self.model.predict(np.array([img]))\n",
        "        return pr_mask\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        try:\n",
        "            self.model.load_weights(weights_path)\n",
        "            print(\"Succesfully loaded weights from {}\".format(weights_path))\n",
        "        except:\n",
        "            orig_weights = \"from Imagenet\"\n",
        "            print(\n",
        "                \"Could not load weights from {}, weights will be loaded {}\".format(\n",
        "                    weights_path, orig_weights\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "zP5TYNyEIRxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}